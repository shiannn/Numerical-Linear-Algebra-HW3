\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Consider the basic iterative method}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}(a) Show that the spectral radius of $G = M^{-1}N$ approximately satisfies $$\rho (G) \approx \genfrac  {}{}{}0{x_{k+1}-x_{k}}{x_{k}-x_{k-1}}$$}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}(b) Show that if $\rho (M^{-1}N)$ is known, an estimate for the error is given by $$\enVert {x_k - x}_2 \leq \genfrac  {}{}{}0{\rho (G)}{1-\rho (G)}\enVert {x_k - x_{k-1}}_2$$ }{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Consider a 500 x 500 sparse matrix A constructed as described in Trefethen and Bau's book on P. 300.}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}(a) Reproduce Fig.38.1 (the CG convergence curves for this matrix) shown at P.}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}(b) Produce a plot for $\tau $ = 0.01, 0.05, 0.1 indicating how closely the above estimates match the actual convergence rate}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}(c) Use the method of steepest descent to solve this linear system again and compare results with those obtained using CG.}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}(d) Redo this problem also using the preconditioned conjugate-gradient method with the gauss-Seidel preconditioner M = D+L. Comments on your results.}{7}}
